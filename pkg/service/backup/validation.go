// Copyright (C) 2017 ScyllaDB

package backup

import (
	"context"
	"encoding/json"
	"net/http"
	"path"
	"time"

	"github.com/pkg/errors"
	"github.com/scylladb/go-log"
	"github.com/scylladb/scylla-manager/pkg/backup"
	"github.com/scylladb/scylla-manager/pkg/scyllaclient"
	"github.com/scylladb/scylla-manager/pkg/service"
	"github.com/scylladb/scylla-manager/pkg/util/parallel"
	"github.com/scylladb/scylla-manager/pkg/util/timeutc"
	"github.com/scylladb/scylla-manager/pkg/util/uuid"
)

// ValidationTarget specifies parameters of location validation process.
type ValidationTarget struct {
	Location            []backup.Location `json:"location"`
	DeleteOrphanedFiles bool              `json:"delete_orphaned_files"`
	Parallel            int               `json:"parallel"`

	liveNodes scyllaclient.NodeStatusInfoSlice
}

// ValidationRunner implements scheduler.Runner.
type ValidationRunner struct {
	service *Service
}

// Run implements scheduler.Runner.
func (r ValidationRunner) Run(ctx context.Context, clusterID, taskID, runID uuid.UUID, properties json.RawMessage) error {
	t, err := r.service.GetValidationTarget(ctx, clusterID, properties)
	if err != nil {
		return errors.Wrap(err, "get validation target")
	}
	_, err = r.service.Validate(ctx, clusterID, taskID, runID, t)
	return err
}

// ValidationRunner creates a Runner that handles backup validation.
func (s *Service) ValidationRunner() ValidationRunner {
	return ValidationRunner{service: s}
}

// GetValidationTarget converts task properties into backup ValidationTarget.
func (s *Service) GetValidationTarget(ctx context.Context, clusterID uuid.UUID, properties json.RawMessage) (ValidationTarget, error) {
	s.logger.Info(ctx, "GetValidationTarget", "cluster_id", clusterID)

	// Unmarshal and make sure location is specified
	var t ValidationTarget
	if err := json.Unmarshal(properties, &t); err != nil {
		return t, err
	}
	if t.Location == nil {
		return t, errors.Errorf("missing location")
	}

	// Get the cluster client
	client, err := s.scyllaClient(ctx, clusterID)
	if err != nil {
		return t, errors.Wrap(err, "get client proxy")
	}

	// Validate validation target and get target nodes...
	liveNodes, err := s.checkValidationTarget(ctx, client, t)
	if err != nil {
		return t, err
	}
	t.liveNodes = liveNodes

	return t, nil
}

// ValidationResult is a summary generated by validator.
type ValidationResult struct {

	Host            string          `json:"host"`
	Location        backup.Location `json:"location"`
	Manifests       int             `json:"manifests"`
	ScannedFiles    int             `json:"scanned_files"`
	BrokenSnapshots []string        `json:"broken_snapshots"`
	MissingFiles    int             `json:"missing_files"`
	OrphanedFiles   int             `json:"orphaned_files"`
	OrphanedBytes   int64           `json:"orphaned_bytes"`
	DeletedFiles    int             `json:"deleted_files"`
	DeleteErrors    int             `json:"delete_errors"`

}

// Validate checks that all SSTable files that are referenced in manifests are
// present. It also checks there are no additional files that somehow leaked
// the purging process. If it finds such files there are removed.
//
// The process is based on listing all files in SSTable directories. This is
// done in parallel, each node works with its data.
func (s *Service) Validate(ctx context.Context, clusterID, taskID, runID uuid.UUID, target ValidationTarget) ([]ValidationResult, error) {
	s.logger.Info(ctx, "Validate",
		"cluster_id", clusterID,
		"task_id", taskID,
		"run_id", runID,
		"target", target,
	)

	// Get the cluster client
	client, err := s.scyllaClient(ctx, clusterID)
	if err != nil {
		return nil, errors.Wrap(err, "get client proxy")
	}

	// Validate if target does not come from GetValidationTarget.
	if len(target.liveNodes) == 0 {
		target.liveNodes, err = s.checkValidationTarget(ctx, client, target)
		if err != nil {
			return nil, err
		}
	}

	// Create hostInfo
	hi, err := makeHostInfo(target.liveNodes, target.Location, nil)
	if err != nil {
		return nil, err
	}

	result := make([]ValidationResult, len(hi))
	return result, parallel.Run(len(hi), target.Parallel, func(i int) error {
		w := newValidator(clusterID, hi[i], client, s.logger.Named("validate").With("host", hi[i].IP))
		if target.DeleteOrphanedFiles {
			w.DeleteOrphanedFiles()
		}
		err := w.Run(ctx)
		result[i] = w.result
		return errors.Wrap(err, hi[i].IP)
	})
}

func (s *Service) checkValidationTarget(ctx context.Context, client *scyllaclient.Client, target ValidationTarget) (scyllaclient.NodeStatusInfoSlice, error) {
	// Get live nodes
	status, err := client.Status(ctx)
	if err != nil {
		return nil, errors.Wrap(err, "get result")
	}
	liveNodes := status.Live()

	// Filter by DC if needed
	var dcs []string
	for _, l := range target.Location {
		if l.DC != "" {
			dcs = append(dcs, l.DC)
		}
	}
	if len(dcs) > 0 {
		liveNodes = liveNodes.Datacenter(dcs)
	}

	// Validate locations access
	if len(liveNodes) == 0 {
		return nil, service.ErrValidate(errors.Errorf("wrong location"))
	}
	if err := s.checkLocationsAvailableFromNodes(ctx, client, liveNodes, target.Location); err != nil {
		return nil, service.ErrValidate(errors.Wrap(err, "location is not accessible"))
	}

	return liveNodes, nil
}

type validator struct {
	clusterID uuid.UUID
	host      hostInfo
	client    *scyllaclient.Client
	logger    log.Logger

	deleteOrphanedFiles bool
	orphanedFiles       fileSet
	result              ValidationResult
}

func newValidator(clusterID uuid.UUID, host hostInfo, client *scyllaclient.Client, logger log.Logger) *validator {
	return &validator{
		clusterID: clusterID,
		host:      host,
		client:    client,
		logger:    logger,

		orphanedFiles: make(fileSet),
		result: ValidationResult{
			Host:     host.IP,
			Location: host.Location,
		},
	}
}

func (w *validator) DeleteOrphanedFiles() {
	w.deleteOrphanedFiles = true
}

func (w *validator) Run(ctx context.Context) error {
	w.logger.Info(ctx, "Start validation", "location", w.host.Location)

	defer func() {
		w.logger.Info(ctx, "Done validation", "result", w.result)
	}()

	start := timeutc.Now()

	// Read manifests
	manifests, err := w.listManifests(ctx)
	if err != nil {
		return errors.Wrap(err, "list manifests")
	}
	files, tempManifestFiles := w.extractFiles(manifests)
	w.result.Manifests = len(manifests)

	// List all files and validate against manifests
	handler := func(item scyllaclient.RcloneListDirItem) {
		w.result.ScannedFiles++

		// File from manifest
		if files.Has(item.Path) {
			files.Remove(item.Path)
			return
		}
		// File from temporary manifest i.e. running backup
		if tempManifestFiles.Has(item.Path) {
			tempManifestFiles.Remove(item.Path)
			return
		}
		// Unexpected file added after we started
		if time.Time(item.ModTime).After(start) {
			w.logger.Info(ctx, "Unexpected new file", "path", item.Path, "mod_time", time.Time(item.ModTime))
			return
		}
		// Orphaned file
		w.result.OrphanedFiles++
		w.result.OrphanedBytes += item.Size
		if w.deleteOrphanedFiles {
			w.orphanedFiles.Add(item.Path)
		}
	}
	if err := w.forEachFile(ctx, handler); err != nil {
		return errors.Wrap(err, "list files")
	}

	// Delete orphaned files if needed
	if w.deleteOrphanedFiles {
		w.orphanedFiles.Each(func(s string) bool {
			if ctx.Err() != nil {
				return false
			}
			if w.deleteFile(ctx, w.host.Location.RemotePath(s)) {
				w.result.DeletedFiles++
			} else {
				w.result.DeleteErrors++
			}
			return true
		})
	}
	if ctx.Err() != nil {
		return ctx.Err()
	}

	// Find broken snapshots
	if missing := files.Size(); missing > 0 {
		w.result.MissingFiles = missing

		affected := w.manifestsWithFiles(manifests, files)
		var tags []string
		for _, m := range affected {
			tags = append(tags, m.SnapshotTag)
		}
		w.result.BrokenSnapshots = tags
		w.logger.Info(ctx, "Found broken snapshots", "snapshot_tags", tags, "files_count", missing)

		files.Each(func(s string) bool {
			w.logger.Info(ctx, "Missing backup file", "path", s)
			return true
		})
	}

	return nil
}

func (w *validator) listManifests(ctx context.Context) ([]*backup.RemoteManifest, error) {
	helper := newMultiVersionManifestLister(w.host.IP, w.host.Location, w.client, w.logger)
	f := ListFilter{
		ClusterID: w.clusterID,
		DC:        w.host.DC,
		NodeID:    w.host.ID,
		Temporary: true,
	}
	return helper.ListManifests(ctx, f)
}

func (w *validator) extractFiles(manifests []*backup.RemoteManifest) (files, tempManifestFiles fileSet) {
	files = make(fileSet)
	tempManifestFiles = make(fileSet)

	for _, m := range manifests {
		var fs fileSet
		if m.Temporary {
			fs = tempManifestFiles
		} else {
			fs = files
		}
		for _, fi := range m.Content.Index {
			fs.DirSet(backup.RemoteSSTableVersionDir(m.ClusterID, m.DC, m.NodeID, fi.Keyspace, fi.Table, fi.Version)).Add(fi.Files...)
		}
	}

	return
}

func (w *validator) forEachFile(ctx context.Context, f func(scyllaclient.RcloneListDirItem)) error {
	baseDir := backup.RemoteSSTableBaseDir(w.clusterID, w.host.DC, w.host.ID)
	opts := scyllaclient.RcloneListDirOpts{
		FilesOnly: true,
		Recurse:   true,
	}
	filesCh, err := w.client.RcloneListDirIter(ctx, w.host.IP, w.host.Location.RemotePath(baseDir), &opts)
	if err != nil {
		return err
	}

	// Context cancellation is handled by RcloneListDirIter
	for {
		v, ok := <-filesCh
		if !ok {
			return nil
		}
		if v.Error != nil {
			return v.Error
		}

		// Prepend path with base dir.
		v.Value.Path = path.Join(baseDir, v.Value.Path)
		f(v.Value)
	}
}

func (w *validator) deleteFile(ctx context.Context, path string) bool {
	w.logger.Debug(ctx, "Deleting file", "path", path)

	if err := w.client.RcloneDeleteFile(ctx, w.host.IP, path); err != nil {
		if scyllaclient.StatusCodeOf(err) != http.StatusNotFound {
			w.logger.Error(ctx, "Delete failed", "path", path, "error", err)
			return false
		}
		w.logger.Info(ctx, "File missing on delete", "path", path)
	}

	return true
}

func (w *validator) manifestsWithFiles(manifests []*backup.RemoteManifest, files fileSet) []*backup.RemoteManifest {
	var out []*backup.RemoteManifest

	for _, m := range manifests {
		// Ignore temporary manifests
		if m.Temporary {
			continue
		}

		for _, fi := range m.Content.Index {
			s := files.DirSet(backup.RemoteSSTableVersionDir(m.ClusterID, m.DC, m.NodeID, fi.Keyspace, fi.Table, fi.Version))
			if s.Size() > 0 && s.HasAny(fi.Files...) {
				out = append(out, m)
				break
			}
		}
	}

	return out
}
